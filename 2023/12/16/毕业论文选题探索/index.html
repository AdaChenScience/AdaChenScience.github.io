<!DOCTYPE html>
<html lang="zh-CN" color-mode="light">

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="author" content="Adachen" />
  <meta name="description" content="Study diaries about 基础数学 应用数学 计算机科学 微观经济学" />
  
  
  <title>
    
      毕业论文选题探索 
      
      
      |
    
     AdaChenScience
  </title>

  
    <link rel="apple-touch-icon" href="/images/favicon.png">
    <link rel="icon" href="/images/favicon.png">
  

  <!-- Raleway-Font -->
  <link href="https://fonts.googleapis.com/css?family=Raleway&display=swap" rel="stylesheet">

  <!-- hexo site css -->
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="//at.alicdn.com/t/font_1886449_67xjft27j1l.css" />
  <!-- 代码块风格 -->
  

  <!-- jquery3.3.1 -->
  
    <script defer type="text/javascript" src="/plugins/jquery.min.js"></script>
  

  <!-- fancybox -->
  
    <link href="/plugins/jquery.fancybox.min.css" rel="stylesheet">
    <script defer type="text/javascript" src="/plugins/jquery.fancybox.min.js"></script>
  
  
<script src="/js/fancybox.js"></script>


  

  

  <script>
    var html = document.documentElement
    const colorMode = localStorage.getItem('color-mode')
    if (colorMode) {
      document.documentElement.setAttribute('color-mode', colorMode)
    }
  </script>
<meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="AdaChenScience" type="application/atom+xml">
</head>


  <body>
    <div id="app">
      <div class="header">
  <div class="avatar">
    <a href="/">
      <!-- 头像取消懒加载，添加no-lazy -->
      
        <img src="/images/guolicheng.png" alt="">
      
    </a>
    <div class="nickname"><a href="/">AdaChen</a></div>
  </div>
  <div class="navbar">
    <ul>
      
        <li class="nav-item" data-path="/">
          <a href="/">Home</a>
        </li>
      
        <li class="nav-item" data-path="/archives/">
          <a href="/archives/">Archives</a>
        </li>
      
        <li class="nav-item" data-path="/categories/">
          <a href="/categories/">Categories</a>
        </li>
      
        <li class="nav-item" data-path="/tags/">
          <a href="/tags/">Tags</a>
        </li>
      
        <li class="nav-item" data-path="/about/">
          <a href="/about/">About</a>
        </li>
      
    </ul>
  </div>
</div>


<script src="/js/activeNav.js"></script>



      <div class="flex-container">
        <!-- 文章详情页，展示文章具体内容，url形式：https://yoursite/文章标题/ -->
<!-- 同时为「标签tag」，「朋友friend」，「分类categories」，「关于about」页面的承载页面，具体展示取决于page.type -->


  <!-- LaTex Display -->

  
    <script async type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    }
  </script>





  <!-- clipboard -->

  
    <script async type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.10/dist/clipboard.min.js"></script>
  
  
<script src="/js/codeCopy.js"></script>







  

  

  

  
  <!-- 文章内容页 url形式：https://yoursite/文章标题/ -->
  <div class="container post-details" id="post-details">
    <div class="post-content">
      <div class="post-title">毕业论文选题探索</div>
      <div class="post-attach">
        <span class="post-pubtime">
          <i class="iconfont icon-updatetime mr-10" title="更新时间"></i>
          2023-12-17 17:50:11
        </span>
        
              <span class="post-categories">
                <i class="iconfont icon-bookmark" title="分类"></i>
                
                <span class="span--category">
                  <a href="/categories/Math/" title="Math">
                    <b>#</b> Math
                  </a>
                </span>
                
              </span>
          
      </div>
      <div class="markdown-body">
        <h1 id="选题资料汇总"><a href="#选题资料汇总" class="headerlink" title="选题资料汇总"></a>选题资料汇总</h1><h2 id="时间线"><a href="#时间线" class="headerlink" title="时间线"></a>时间线</h2><ul>
<li>10月中旬确认导师</li>
<li>11月中旬浏览各种方向&#x2F;书籍  </li>
<li>12月27日选题入系统</li>
<li>1月4日开题答辩</li>
<li>3月20日中期考核</li>
<li>4月22日论文上传</li>
<li>5月15日前论文答辩</li>
</ul>
<h2 id="方向一：往届论文"><a href="#方向一：往届论文" class="headerlink" title="方向一：往届论文"></a>方向一：往届论文</h2><ol>
<li><p><strong>题目</strong>：一类随机分布式参数<br>估计算法的收敛性研究<br><strong>主题</strong>：分析带噪声的分布式参数估计算法的收敛性<br><strong>应用</strong>：物联网和电网<br><strong>前置知识</strong>： 鞅收敛理论、代数图论、随机时变系统理论<br><strong>待完成</strong>：分析算法的收敛速度，在加性噪声的基础上同时考虑乘性噪声。</p>
</li>
<li><p><strong>题目</strong>Convergence of Policy Gradient Methods<br>for Nash Equilibria in General-sum<br>Stochastic Games<br><strong>主题</strong>：Nash equilibria learning of a general-sum stochastic game with an unknown<br>transition probability density function<br><strong>亮点</strong>：通过纳什均衡和变分不等式问题的等价性设计了一个双循环算法。<br><strong>前置知识</strong>：</p>
</li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variational_inequality">纳什均衡（Nash Equilibrium）</a>：在博弈论中，纳什均衡是一种策略组合，其中每个玩家的策略都是在假设其他所有玩家保持其策略不变的情况下的最佳反应</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Variational_inequality">变分不等式（Variational Inequality）</a>：变分不等式是一种涉及泛函的不等式，必须为给定变量的所有可能值求解，这些值通常属于一个凸集</li>
<li><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10957-017-1124-1">Minty变分不等式（Minty Variational Inequality）</a>：变分不等式的一种，它在解决变分不等式问题的投影类型算法中起着关键作用</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1403.3390.pdf">额外梯度算法（Extragradient Algorithm）</a>：额外梯度算法是一种用于求解某些优化问题的迭代方法，特别是用于求解变分不等式问题。在每次迭代中，该算法都会计算函数的梯度（或者更一般地说，是某个适当的“方向”），然后沿着这个方向进行一步。<br><strong>论文中知识点</strong></li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Markov_decision_process">马尔可夫决策过程（Markov Decision Process）</a>：马尔可夫决策过程是一种离散时间随机控制过程，模拟了在结果部分随机、部分受决策者控制的情况下的决策制定</li>
<li><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/markov-decision-process/">代理（Agent）</a>：在马尔可夫决策过程中，代理是指做出决策的实体</li>
<li>策略（Policy）：策略是解决马尔可夫决策过程的一种方法。策略是从状态空间到动作空间的映射。它指示在状态S时应采取的动作’a’</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Stochastic_game">随机博弈（Stochastic Games）</a>：随机博弈是一种由一个或多个玩家进行的具有概率转换的重复博弈。游戏是按阶段进行的。在每个阶段开始时，游戏处于某种状态。玩家选择行动，每个玩家收到的收益取决于当前状态和所选行动。然后，游戏转移到一个新的随机状态，其分布取决于前一个状态和玩家选择的行动。在新状态下重复这个过程，并且游戏继续进行有限或无限的阶段  </li>
<li><a target="_blank" rel="noopener" href="https://isminoula.github.io/files/games.pdf">马尔可夫博弈（Markov Games）</a>：马尔可夫博弈是随机博弈的另一种称呼，它允许人们将马尔可夫决策过程扩展到具有多个代理的情况</li>
<li>状态转移概率密度函数（State Transition Probability Density Function）：在随机过程中，状态转移概率密度函数描述了系统从一个状态转移到另一个状态的概率。在强化学习中，这个函数通常被用来描述环境的动态性，即在给定当前状态和行动的情况下，系统将转移到哪个新状态的概率。</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Multi-agent_reinforcement_learning">多代理强化学习（Multi-Agent Reinforcement Learning）</a>：多代理强化学习是强化学习的一个子领域，研究的是在一个共享环境中多个学习代理的行为。这个领域结合了寻找理想算法以最大化奖励的追求，以及一套更社会化的概念，如合作、互惠、公平、社会影响和语言.</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Q-learning">Q学习（Q-Learning）</a>：Q学习是一种模型自由的强化学习算法，用于学习在特定状态下行动的价值。它不需要环境的模型，可以处理随机的转换和奖励。它可以为任何马尔可夫决策过程确定一个最优策略，只要有无限的探索时间和部分随机的策略。</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/148489261">演员-评论家（Actor-Critic）</a>：是一种强化学习算法，其中有两个主要组成部分：演员（Actor）和评论家（Critic）。演员负责根据当前的环境状态选择一个行动，而评论家则评估这个行动的好坏，并给出反馈，以此来更新演员的策略</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1906.06659.pdf">两人一般和随机博弈（Two-Player General-Sum Stochastic Games）</a>：两人一般和随机博弈是一种博弈形式，其中两个玩家的支付（即他们的收益或损失）通常是不相关的。如果一个玩家的支付是另一个玩家支付的负数，那么这个博弈就会简化为零和博弈。在这种博弈中，每个玩家的目标通常是最大化他们自己的总支付。</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.10554v1">Nash Q-Learning (NashQ)</a>: 这一种基于Q学习的算法，用于在一般和随机游戏中找到纳什均衡</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53563792">Friend or Foe Q-Learning (FFQ)</a>: 一种从Minimax-Q算法扩展而来的算法，它将所有的智能体分为两组，一组为智能体的朋友（帮助智能体一起最大化其奖励），另一组为智能体的敌人（对抗智能体并降低其奖励）</li>
<li><a target="_blank" rel="noopener" href="https://aaai.org/papers/icml03-034-correlated-q-learning/">Correlated Q-Learning</a>: 一种基于相关均衡（CE）解决方案概念的多智能体Q学习算法。CE-Q概括了Nash-Q和Friend-and-Foe-Q：在一般和游戏中，相关均衡的集合包含了纳什均衡的集合</li>
<li><a target="_blank" rel="noopener" href="https://gurpreet-ai.github.io/action-state-value-function-bellman-equation-optimal-functions-deep-reinforcement-learning-series/">动作-价值函数（Action-Value Functions）</a>：动作-一个函数，它返回在某个状态下使用某个动作时遵循某个策略的预期回报。动作-价值函数与价值函数紧密相关，通过Bellman最优性方程进行定义</li>
<li><a href="%22http://www.scholarpedia.org/article/Policy_gradient_methods">策略梯度方法（Policy Gradient Methods）</a>：一种强化学习技术，它依赖于通过梯度下降对预期回报（长期累积奖励）进行优化的参数化策略.优点是可以选择有意义的策略表示，通常在学习过程中需要的参数比基于价值函数的方法少</li>
<li><a target="_blank" rel="noopener" href="https://ai.stackexchange.com/questions/20968/what-does-it-mean-to-parameterise-a-policy-in-policy-gradient-methods">策略参数化（Policy Parameterization）</a>：在强化学习中，策略参数化是指使用一组参数来表示策略。这些参数可以是神经网络的权重，也可以是其他类型的模型参数。通过改变这些参数，可以改变策略的行为</li>
<li><a target="_blank" rel="noopener" href="https://ai.stackexchange.com/questions/20968/what-does-it-mean-to-parameterise-a-policy-in-policy-gradient-methods">状态-价值函数（State-Value Functions）</a>：函数返回在某个状态下遵循某个策略的预期回报</li>
<li><strong>直接参数化和α-贪婪参数化</strong>：在强化学习中使用的策略类型，其中策略是由参数决定的函数。<strong>直接参数化</strong>是指策略直接作为参数的函数，<strong>α-贪婪参数化</strong>是指策略在大多数情况下选择最优动作，但有时会以一定的概率选择非最优动作  </li>
<li><strong>紧凑和凸的状态和动作空间</strong>：假设问题的解空间（在这种情况下是状态和动作空间）是紧凑的和凸的。紧凑性意味着空间是有界闭的，这使得我们可以在有限的范围内搜索解。</li>
<li><strong>势函数</strong>：在博弈论中，势函数将博弈的每个策略配置映射到一个实数，使得任何单个玩家从一个策略配置改变到另一个策略配置的效用变化等于势函数在这两点之间的差异</li>
<li><strong>马尔可夫势博弈</strong>：一种特殊类型的博弈，其中玩家的支付不仅取决于所有玩家的联合行动，还取决于遵循马尔可夫过程的状态变量</li>
<li><strong>变分不等式问题</strong>：一种优化问题，其中寻找一个解，使得一个给定的函数在解的方向上的梯度大于或等于零。</li>
<li><strong>强单调变分不等式</strong>：一种变分不等式，其中函数的梯度不仅满足单调性条件，而且还满足一种强度条件，这使得解的存在性和唯一性得到保证</li>
<li><strong>近端参数</strong>：一种在优化算法中使用的参数，帮助算法更好地处理如非光滑问题或具有约束的问题</li>
<li><strong>k 1&#x2F;2 -加权渐近纳什均衡</strong>：一种纳什均衡的概念，在这种均衡中，玩家的策略是按照k 1&#x2F;2 的权重进行加权的</li>
</ul>
<h3 id="关联方向："><a href="#关联方向：" class="headerlink" title="关联方向："></a>关联方向：</h3><ol>
<li><a target="_blank" rel="noopener" href="https://link.springer.com/article/10.1007/s10462-021-09996-w">多智能体强化学习</a>：（MARL）可以用于解决网络资源分配和共享、网络路由和交通信号控制等复杂的实际问题。互联网行业：应用于智能驾驶、智能工厂等。业界：DeepMind、OpenAI等公司  </li>
<li><a target="_blank" rel="noopener" href="https://www.geeksforgeeks.org/stochastic-games-in-artificial-intelligence/">随机博弈</a>：如掷骰子，有随机元素，可以看作是随机博弈随机博弈可以应用于在线广告投放、网络流量控制等领域</li>
<li><a target="_blank" rel="noopener" href="https://www.frontiersin.org/articles/10.3389/frobt.2018.00049/full">参数化策略和优化</a>：可以通过参数化技能来初始化优化过程，从而更有效地进行任务学习.应用于推荐系统、广告投放等领域</li>
<li><a target="_blank" rel="noopener" href="https://www.hindawi.com/journals/aaa/si/737029/">变分不等式和优化问题</a>：可以应用于网络流量控制、资源分配等领域.</li>
</ol>
<h3 id="学习资源运筹学与控制论的科普"><a href="#学习资源运筹学与控制论的科普" class="headerlink" title="学习资源运筹学与控制论的科普"></a>学习资源<a target="_blank" rel="noopener" href="https://www.zhihu.com/column/c_1099378515039928320">运筹学与控制论的科普</a></h3><ul>
<li>运筹学规划部分（已学）</li>
<li>最优化方法(需学习代码)</li>
<li>鲁棒优化(待学)</li>
<li>强化学习CS285笔记(待学)</li>
</ul>
<h2 id="方向二、多智能体强化学习"><a href="#方向二、多智能体强化学习" class="headerlink" title="方向二、多智能体强化学习"></a>方向二、多智能体强化学习</h2><h3 id="综述："><a href="#综述：" class="headerlink" title="综述："></a>综述：</h3><ol>
<li>知乎<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/349092158">多智能体强化学习路线图2021</a></li>
<li>知乎<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/373368383">多智能体系统协同控制2021</a></li>
<li>UCL<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.00583.pdf">An Overview of Multi-agent Reinforcement Learning<br>from Game Theoretical Perspective
</a></li>
</ol>
<h3 id="论文："><a href="#论文：" class="headerlink" title="论文："></a>论文：</h3><ol>
<li>（2019SJTU计算机本科）<br><strong>基于合作式多智体交互的自监督学习：</strong><br><strong>简介</strong>：<br>让生成式对抗网络（Generative Adversarial Networks, GANs）<br>人们对于概率分布的度量有了更加深入的思考和认识。<br>传统观点下，由于原始版本的生成式对抗网络只能够<strong>建模连续的数据分布</strong>，即分布中每一个样本均可以梯度方式进行修改和更新。因此，生成式对抗网络最初在文本生成及一般的概率建模问题上并没有什么建树。2016 年，随着基于无模型强化学习的序列<br>生成式对抗网络（Sequence Generative Adversarial Network）的提出，这一问题得到了初步的解决。然而，这个算法有着不小的进步空间。<br>本文提出一个通用的框架，即基于<strong>合作式多智体交互的自监督学习</strong>(Cooperative<br>Multi-agent Self-supervised Learning)，用以解决离散数据不能被之前的算法有效<br>建模的问题。  </li>
<li><strong>multi-person 3d motion</strong>：<a href="%22http://cfcs.pku.edu.cn/news/241764.htm">NeurIPS 2023 入选论文解读：认知层级下的群体动作预测</a>:　<br><strong>背景</strong>：在社交环境中，人类会下意识地预测他人的行为，并据此开展自己的行为决策。这种能力使得个体能够在各种场景中与他人合作或竞争，从行人交通到团队运动等。研究者们提出了预测<strong>多智能体未来行为</strong>的任务。大部分先前的工作主要集中在<strong>对象轨迹层面的互动建模和预测</strong>，在自动驾驶等应用中取得了显著的成果。然而，基于轨迹的方法只能反映粗粒度的互动（例如避免碰撞、保持社交距离等），并未捕捉到丰富的人类动作细节。</li>
</ol>
<h3 id="知乎相关话题："><a href="#知乎相关话题：" class="headerlink" title="知乎相关话题："></a>知乎相关话题：</h3><ol>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/29727968">机器学习，神经网络在控制科学中的前景和应用大吗？</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/384309057">多智能体协同控制未来的前景和方向如何？</a>  </li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/27269292">关于多智能体领域你的看法是什么？</a></li>
</ol>
<h2 id="方向三、强化学习（deepRL-分布式RL）"><a href="#方向三、强化学习（deepRL-分布式RL）" class="headerlink" title="方向三、强化学习（deepRL,分布式RL）"></a>方向三、强化学习（deepRL,分布式RL）</h2><p><strong>学习资源</strong>：  </p>
<ol>
<li><a target="_blank" rel="noopener" href="https://spinningup.openai.com/en/latest/index.html">OpenAI强化学习文档</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/52410530">知乎：OpenAI-Maddpg原理与实现</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/344196096">知乎：强化学习路线2021</a></li>
<li>B站：传统方法是否过时？强化学习落地的前景与挑战？<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Xu4y1F72H/?spm_id_from=333.880.my_history.page.click&vd_source=1f9dd3e3e831d4b4dada2c44f86b9707">第一届自主机器人技术研讨会圆桌论坛</a>(无人机&#x2F;机器人讨论会)</li>
<li>B站<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1sd4y167NS/?vd_source=1f9dd3e3e831d4b4dada2c44f86b9707">强化学习的数学原理</a>(非常基础)</li>
<li><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV12o4y197US/?spm_id_from=333.337.search-card.all.click&vd_source=1f9dd3e3e831d4b4dada2c44f86b9707">【王树森】深度强化学习(DRL)</a>:基本概念、价值学习、策略学习、Actor-Critic方法、AlphaGo、Monte Carlo (蒙特卡洛)</li>
<li><a target="_blank" rel="noopener" href="https://book.douban.com/subject/35271383/">看过的图书2020</a><img src="https://img2.doubanio.com/view/subject/l/public/s33768761.jpg" alt="分布式人工智能"></li>
</ol>
<ul>
<li>第1章 分布式系统简介</li>
<li>第2章 分布式智能计算基础</li>
<li>第3章 TensorFlow框架介绍</li>
<li>第4章 分布式智能计算核心</li>
<li>第5章 大数据与存储系统框架</li>
<li>第6章 机器学习算法与分布式改进</li>
<li>第7章 生成网络和强化学习</li>
<li>第8章 对抗和群体智能博弈</li>
<li>第9章 体验群体智能对抗仿真环境</li>
<li>第10章 开发群体智能仿真对抗系统<br><strong>看到的文章</strong></li>
</ul>
<ol>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/pFxAq28s2OeKXlLV1-FmKQ">ICML 2023 | RACE</a>:使用进化算法大幅提升多智能体强化学习算法学习<br><a href="%22http://icdai.org/">天津大学强化学习实验室</a>提出多智能体进化强化学习混合框架 RACE。该框架充分融合了进化算法与多智能体强化学习用于多智能体协作，并首次在复杂控制任务上证明了进化算法可以进一步提升 MARL 的性能</li>
</ol>
<h2 id="方向四、AI-agent"><a href="#方向四、AI-agent" class="headerlink" title="方向四、AI-agent"></a>方向四、AI-agent</h2><h3 id="综述：-1"><a href="#综述：-1" class="headerlink" title="综述："></a>综述：</h3><ol>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648376562">LLM-based Agents survey 基于大语言模型多智能代理简单综述及展望</a>2023.08</li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/657937696">读懂AI Agent：基于大模型的人工智能代理</a>2023.09</li>
</ol>
<h3 id="看到的文章："><a href="#看到的文章：" class="headerlink" title="看到的文章："></a>看到的文章：</h3><ol>
<li><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/9D80OCidvDwKyQjKYtOklg">NeurIPS 2023 | AI Agents先行者CAMEL</a>首个基于大模型的多智能体框架:<br>介绍了 KAUST 团队的大模型心智交互 CAMEL 框架（“骆驼”）,重点探索了一种称为<strong>角色扮演（role-playing）</strong>的新型合作代理框架，该框架可以有效缓解智能体<strong>对话过程中出现的错误现象</strong>，从而有效引导智能体完成各种复杂的任务，人类用户只需要<strong>输入一个初步的想法</strong>就可以启动整个过程。</li>
<li>清华NLP<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/KpISuu-HPkgvsZtFBYWcnA">Agentic Process Automation</a>:<br>将 Agent 技术的灵活性引入到 <strong>RPA(Robotic Process Automation)领域中</strong>,实现了一个自动化智能体 ProAgent，其可以接收人类指令，以生成代码的方式构建工作流，同在工作流中引入 DataAgent 和 ControlAgent 来在工作流中实现<strong>复杂数据处理与逻辑控制</strong>。</li>
</ol>
<h3 id="研究能力要求："><a href="#研究能力要求：" class="headerlink" title="研究能力要求："></a>研究能力要求：</h3><ul>
<li>清华大学未来实验室：<br><strong>研究内容</strong>：面向人机交互的AI Agent智能体系统研究：</li>
</ul>
<ol>
<li>大语言模型LLM本地化部署、微调及特定领域数据构建；</li>
<li>针对Agent、LLM的前沿技术调研及对话式交互理论研究；</li>
<li>任务导向的LLM-based Agent系统研发及评估；</li>
<li>参与用户研究、用户实验及学术文章撰写等工作。</li>
<li>熟练掌握R、Python、C＋＋等一种或多种程序开发语言，能够熟练进行数据分析、数据清洗；</li>
<li>熟悉深度学习、自然语言处理，有良好的编程能力和算法基础；</li>
<li>熟悉熟悉linux操作系统，有相关工程经历者优先；</li>
<li>有LLM微调、In-Context-Learning、Chain of Thought、langchain及大模型应用相关项目经验者</li>
</ol>
<h2 id="其他材料"><a href="#其他材料" class="headerlink" title="其他材料"></a>其他材料</h2><ol>
<li>讲座<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Rz4y1E7CU/?spm_id_from=333.337.search-card.all.click&vd_source=1f9dd3e3e831d4b4dada2c44f86b9707">面向能源互联网的状态估计和经济调度算法</a>  </li>
<li>公众号文章<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/BXQVY7rjlwjAkSxWg_dtcQ">大语言模型的数学之路</a>:</li>
</ol>
<ul>
<li>LLM 目前在数学问题上取得的进展；</li>
<li>有哪些技术路线在未来可能会更进一步提升 LLM 解决数学问题的能力？</li>
</ul>
<ol start="3">
<li>眼球追踪技术(已经开发系统)，可合作解决关于数学的部分</li>
<li>论文是否可应用于以下方向：</li>
</ol>
<ul>
<li><p>智能电网与可再生能源领域</p>
</li>
<li><p>工业工程与运筹学领域</p>
</li>
<li><p>智能交通与物流领域</p>
</li>
<li><p>低碳经济与金融风险分析研究领域</p>
</li>
<li><p>大数据与人工智能领域</p>
</li>
<li><p>计算机系统研究领域</p>
</li>
</ul>

      </div>
      
        <div class="prev-or-next">
          <div class="post-foot-next">
            
              <a href="/2023/12/06/%E2%80%9C%E5%BE%AE%E8%A7%82%E7%BB%8F%E6%B5%8E%E5%AD%A6%EF%BC%9A%E4%BF%A1%E6%81%AF%E4%B8%8D%E5%AF%B9%E7%A7%B0%E2%80%9D/" target="_self">
                <i class="iconfont icon-chevronleft"></i>
                <span>上一页</span>
              </a>
            
          </div>
          <div class="post-attach">
            <span class="post-pubtime">
              <i class="iconfont icon-updatetime mr-10" title="更新时间"></i>
              2023-12-17 17:50:11
            </span>
            
                  <span class="post-categories">
                    <i class="iconfont icon-bookmark" title="分类"></i>
                    
                    <span class="span--category">
                      <a href="/categories/Math/" title="Math">
                        <b>#</b> Math
                      </a>
                    </span>
                    
                  </span>
              
          </div>
          <div class="post-foot-prev">
            
          </div>
        </div>
      
    </div>
    
  <div id="btn-catalog" class="btn-catalog">
    <i class="iconfont icon-catalog"></i>
  </div>
  <div class="post-catalog hidden" id="catalog">
    <div class="title">目录</div>
    <div class="catalog-content">
      
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%80%89%E9%A2%98%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB"><span class="toc-text">选题资料汇总</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%97%B6%E9%97%B4%E7%BA%BF"><span class="toc-text">时间线</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%90%91%E4%B8%80%EF%BC%9A%E5%BE%80%E5%B1%8A%E8%AE%BA%E6%96%87"><span class="toc-text">方向一：往届论文</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E8%81%94%E6%96%B9%E5%90%91%EF%BC%9A"><span class="toc-text">关联方向：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E8%BF%90%E7%AD%B9%E5%AD%A6%E4%B8%8E%E6%8E%A7%E5%88%B6%E8%AE%BA%E7%9A%84%E7%A7%91%E6%99%AE"><span class="toc-text">学习资源运筹学与控制论的科普</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%90%91%E4%BA%8C%E3%80%81%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0"><span class="toc-text">方向二、多智能体强化学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E8%BF%B0%EF%BC%9A"><span class="toc-text">综述：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%EF%BC%9A"><span class="toc-text">论文：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9F%A5%E4%B9%8E%E7%9B%B8%E5%85%B3%E8%AF%9D%E9%A2%98%EF%BC%9A"><span class="toc-text">知乎相关话题：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%90%91%E4%B8%89%E3%80%81%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%EF%BC%88deepRL-%E5%88%86%E5%B8%83%E5%BC%8FRL%EF%BC%89"><span class="toc-text">方向三、强化学习（deepRL,分布式RL）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%90%91%E5%9B%9B%E3%80%81AI-agent"><span class="toc-text">方向四、AI-agent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E8%BF%B0%EF%BC%9A-1"><span class="toc-text">综述：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9C%8B%E5%88%B0%E7%9A%84%E6%96%87%E7%AB%A0%EF%BC%9A"><span class="toc-text">看到的文章：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A0%94%E7%A9%B6%E8%83%BD%E5%8A%9B%E8%A6%81%E6%B1%82%EF%BC%9A"><span class="toc-text">研究能力要求：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%B6%E4%BB%96%E6%9D%90%E6%96%99"><span class="toc-text">其他材料</span></a></li></ol></li></ol>
      
    </div>
  </div>

  
<script src="/js/catalog.js"></script>




    
      <div class="comments-container">
        




  
    <script async type="text/javascript" src='https://cdn.jsdelivr.net/npm/valine@1.4.18/dist/Valine.min.js' onload="loadValineSuc(this)"></script>
  

  <div id="vcomments"></div>

  <script>
    function loadValineSuc() {
      new Valine({
        el: '#vcomments',
        appId: 'kxiCpx601e7xYMFT921Oj67h-gzGzoHsz',
        appKey: 'OHVPXFhOftLL67dLcYUwLj6H',
        placeholder: 'Welcome!随便写点什么吧~',
        avatar: 'retro',
        lang: 'zh-CN'
      })
    }
  </script>

    <style>
      .comments-container .v .vempty {
        display: none!important;
      }
    </style>




      </div>
    
  </div>


        
<div class="footer">
  <div class="social">
    <ul>
      
        <li>
          
              <a title="github" target="_blank" rel="noopener" href="https://github.com/AdaChenScience">
                <i class="iconfont icon-github"></i>
              </a>
              
        </li>
        
        <li>
          
            <a title="email" href="mailto:chengchenc96@gmail.com">
              <i class="iconfont icon-envelope"></i>
            </a>
            
        </li>
        
        <li>
          
              <a title="rss" href="/atom.xml">
                <i class="iconfont icon-rss"></i>
              </a>
              
        </li>
        
    </ul>
  </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Copyright © 2023 Oranges</a>
        
    </div>
  
    
    <div class="footer-more">
      
        <a target="_blank" rel="noopener" href="https://github.com/zchengsite/hexo-theme-oranges">Theme by Oranges | Powered by Hexo</a>
        
    </div>
  
  
</div>

      </div>

      <div class="tools-bar">
        <div class="back-to-top tools-bar-item hidden">
  <a href="javascript: void(0)">
    <i class="iconfont icon-chevronup"></i>
  </a>
</div>


<script src="/js/backtotop.js"></script>



        
  <div class="search-icon tools-bar-item" id="search-icon">
    <a href="javascript: void(0)">
      <i class="iconfont icon-search"></i>
    </a>
  </div>

  <div class="search-overlay hidden">
    <div class="search-content" tabindex="0">
      <div class="search-title">
        <span class="search-icon-input">
          <a href="javascript: void(0)">
            <i class="iconfont icon-search"></i>
          </a>
        </span>
        
          <input type="text" class="search-input" id="search-input" placeholder="搜索">
        
        <span class="search-close-icon" id="search-close-icon">
          <a href="javascript: void(0)">
            <i class="iconfont icon-close"></i>
          </a>
        </span>
      </div>
      <div class="search-result" id="search-result"></div>
    </div>
  </div>

  <script type="text/javascript">
    var inputArea = document.querySelector("#search-input")
    var searchOverlayArea = document.querySelector(".search-overlay")

    inputArea.onclick = function() {
      getSearchFile()
      this.onclick = null
    }

    inputArea.onkeydown = function() {
      if(event.keyCode == 13)
        return false
    }

    function openOrHideSearchContent() {
      let isHidden = searchOverlayArea.classList.contains('hidden')
      if (isHidden) {
        searchOverlayArea.classList.remove('hidden')
        document.body.classList.add('hidden')
        // inputArea.focus()
      } else {
        searchOverlayArea.classList.add('hidden')
        document.body.classList.remove('hidden')
      }
    }

    function blurSearchContent(e) {
      if (e.target === searchOverlayArea) {
        openOrHideSearchContent()
      }
    }

    document.querySelector("#search-icon").addEventListener("click", openOrHideSearchContent, false)
    document.querySelector("#search-close-icon").addEventListener("click", openOrHideSearchContent, false)
    searchOverlayArea.addEventListener("click", blurSearchContent, false)

    var searchFunc = function (path, search_id, content_id) {
      'use strict';
      var $input = document.getElementById(search_id);
      var $resultContent = document.getElementById(content_id);
      $resultContent.innerHTML = "<ul><span class='local-search-empty'>首次搜索，正在载入索引文件，请稍后……<span></ul>";
      $.ajax({
        // 0x01. load xml file
        url: path,
        dataType: "xml",
        success: function (xmlResponse) {
          // 0x02. parse xml file
          var datas = $("entry", xmlResponse).map(function () {
            return {
              title: $("title", this).text(),
              content: $("content", this).text(),
              url: $("url", this).text()
            };
          }).get();
          $resultContent.innerHTML = "";

          $input.addEventListener('input', function () {
            // 0x03. parse query to keywords list
            var str = '<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length <= 0) {
              return;
            }
            // 0x04. perform local searching
            datas.forEach(function (data) {
              var isMatch = true;
              var content_index = [];
              if (!data.title || data.title.trim() === '') {
                data.title = "Untitled";
              }
              var orig_data_title = data.title.trim();
              var data_title = orig_data_title.toLowerCase();
              var orig_data_content = data.content.trim().replace(/<[^>]+>/g, "");
              var data_content = orig_data_content.toLowerCase();
              var data_url = data.url;
              var index_title = -1;
              var index_content = -1;
              var first_occur = -1;
              // only match artiles with not empty contents
              if (data_content !== '') {
                keywords.forEach(function (keyword, i) {
                  index_title = data_title.indexOf(keyword);
                  index_content = data_content.indexOf(keyword);

                  if (index_title < 0 && index_content < 0) {
                    isMatch = false;
                  } else {
                    if (index_content < 0) {
                      index_content = 0;
                    }
                    if (i == 0) {
                      first_occur = index_content;
                    }
                    // content_index.push({index_content:index_content, keyword_len:keyword_len});
                  }
                });
              } else {
                isMatch = false;
              }
              // 0x05. show search results
              if (isMatch) {
                str += "<li><a href='" + data_url + "' class='search-result-title'>" + orig_data_title + "</a>";
                var content = orig_data_content;
                if (first_occur >= 0) {
                  // cut out 100 characters
                  var start = first_occur - 20;
                  var end = first_occur + 80;

                  if (start < 0) {
                    start = 0;
                  }

                  if (start == 0) {
                    end = 100;
                  }

                  if (end > content.length) {
                    end = content.length;
                  }

                  var match_content = content.substr(start, end);

                  // highlight all keywords
                  keywords.forEach(function (keyword) {
                    var regS = new RegExp(keyword, "gi");
                    match_content = match_content.replace(regS, "<span class=\"search-keyword\">" + keyword + "</span>");
                  });

                  str += "<p class=\"search-result-abstract\">" + match_content + "...</p>"
                }
                str += "</li>";
              }
            });
            str += "</ul>";
            if (str.indexOf('<li>') === -1) {
              return $resultContent.innerHTML = "<ul><span class='local-search-empty'>没有找到内容，请尝试更换检索词。<span></ul>";
            }
            $resultContent.innerHTML = str;
          });
        },
        error: function(xhr, status, error) {
          $resultContent.innerHTML = ""
          if (xhr.status === 404) {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>未找到search.xml文件，具体请参考：<a href='https://github.com/zchengsite/hexo-theme-oranges#configuration' target='_black'>configuration</a><span></ul>";
          } else {
            $resultContent.innerHTML = "<ul><span class='local-search-empty'>请求失败，尝试重新刷新页面或稍后重试。<span></ul>";
          }
        }
      });
      $(document).on('click', '#search-close-icon', function() {
        $('#search-input').val('');
        $('#search-result').html('');
      });
    }

    var getSearchFile = function() {
        var path = "/search.xml";
        searchFunc(path, 'search-input', 'search-result');
    }
  </script>




        
  <div class="tools-bar-item theme-icon" id="switch-color-scheme">
    <a href="javascript: void(0)">
      <i id="theme-icon" class="iconfont icon-moon"></i>
    </a>
  </div>

  
<script src="/js/colorscheme.js"></script>





        
  
    <div class="share-icon tools-bar-item">
      <a href="javascript: void(0)" id="share-icon">
        <i class="iconfont iconshare"></i>
      </a>
      <div class="share-content hidden">
        
          <a class="share-item" href="https://twitter.com/intent/tweet?text=' + %E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87%E9%80%89%E9%A2%98%E6%8E%A2%E7%B4%A2 + '&url=' + https%3A%2F%2Fadachenscience.github.io%2F2023%2F12%2F16%2F%25E6%25AF%2595%25E4%25B8%259A%25E8%25AE%25BA%25E6%2596%2587%25E9%2580%2589%25E9%25A2%2598%25E6%258E%25A2%25E7%25B4%25A2%2F + '" target="_blank" title="Twitter">
            <i class="iconfont icon-twitter"></i>
          </a>
        
        
          <a class="share-item" href="https://www.facebook.com/sharer.php?u=https://adachenscience.github.io/2023/12/16/%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87%E9%80%89%E9%A2%98%E6%8E%A2%E7%B4%A2/" target="_blank" title="Facebook">
            <i class="iconfont icon-facebooksquare"></i>
          </a>
        
      </div>
    </div>
  
  
<script src="/js/shares.js"></script>



      </div>
    </div>
  </body>
</html>
